{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN分类，LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-17T06:43:37.337Z"
    }
   },
   "outputs": [],
   "source": [
    "#RNN分类,LSTM\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "EPOCH=1\n",
    "BATCH_SIZE=64\n",
    "TIME_STEP=28     #RNN time step/image height,从上到下一行行扫像素点\n",
    "INPUT_SIZE=28    #RNN input size/image width\n",
    "LR=0.01\n",
    "DOWNLOAD_MNIST=True\n",
    "\n",
    "train_data=dsets.MNIST(root='./mnist',train=True,transform=transforms.ToTensor(),download=DOWNLOAD_MNIST)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True,)\n",
    "\n",
    "test_data=dsets.MNIST(root='./mnist',train=False,transform=transforms.ToTensor())\n",
    "test_x=Variable(test_data.test_data,volatile=True).type(torch.FloatTensor)[:2000]/255\n",
    "test_y=test_data.test_labels.numpy()[:2000]\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.rnn=nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,    #RNN hidden units\n",
    "            num_layers=1,       #RNN layer\n",
    "            batch_first=True  #input,output会带上batch作为第一维度 (batch, time_step, input_size)            \n",
    "        )\n",
    "        \n",
    "        self.out=nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size/hidden_size)\n",
    "        # h_n，h_c shape (n_layers, batch, hidden_size)为长短期记忆的分线和主线的hidden state\n",
    "       \n",
    "        r_out,(h_n,h_c)=self.rnn(x,None)#none代表没有初始的hidden state\n",
    "        out=self.out(r_out[:,-1,:])#要最后一个time step的输出\n",
    "        return out\n",
    "\n",
    "rnn=RNN()\n",
    "print(test_x.size())\n",
    "print(rnn(test_x[:2]))\n",
    "\n",
    "\n",
    "optimizer=torch.optim.Adam(rnn.parameters(),lr=LR)\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(b_x,b_y)in enumerate(train_loader):\n",
    "        b_x=Variable(b_x.view(-1,28,28))#(64,1,28,28)-->(64,28,28)前面乘一起\n",
    "        b_y=Variable(b_y)\n",
    "        output=rnn(b_x)\n",
    "        loss=loss_func(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "\n",
    "\n",
    "test_output = rnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN回归**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-17T06:43:45.223Z"
    }
   },
   "outputs": [],
   "source": [
    "#RNN回归\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEP=10  #RNN time step\n",
    "INPUT_SIZE=1  #RNN input size\n",
    "LR=0.02\n",
    "\n",
    "steps=np.linspace(0,np.pi*2,100,dtype=np.float32)\n",
    "x_np=np.sin(steps)\n",
    "y_np=np.cos(steps)\n",
    "plt.plot(steps,y_np,'r-',label='target(cos)')\n",
    "plt.plot(steps,x_np,'b-',label='input(sin)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.rnn=nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out=nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x,h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out,h_state=self.rnn(x,h_state)\n",
    "        \n",
    "        outs=[]#保存所有的预测\n",
    "        for time_step in range(r_out.size(1)):\n",
    "            outs.append(self.out(r_out[:,time_step,:]))\n",
    "        return torch.stack(outs,dim=1),h_state#把list转换为tensor,合并在一起，保留r_out\n",
    "         # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # outs = outs.view(-1, TIME_STEP, 1)\n",
    "        # return outs, h_state\n",
    "        \n",
    "        # or even simpler, since nn.Linear can accept inputs of any dimension \n",
    "        # and returns outputs with same dimension except for the last\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs\n",
    "\n",
    "rnn=RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer=torch.optim.Adam(rnn.parameters(),lr=LR)\n",
    "loss_func=nn.MSELoss()\n",
    "\n",
    "h_state=None #初始化\n",
    "\n",
    "plt.figure(1, figsize=(12, 5))\n",
    "plt.ion() \n",
    "\n",
    "for step in range(100):\n",
    "    start,end=step*np.pi,(step+1)*np.pi\n",
    "    steps=np.linspace(start,end,TIME_STEP,dtype=np.float32,endpoint=False)\n",
    "    x_np=np.sin(steps)\n",
    "    y_np=np.cos(steps)\n",
    "    \n",
    "    x=Variable(torch.from_numpy(x_np[np.newaxis,:,np.newaxis]))\n",
    "    y=Variable(torch.from_numpy(y_np[np.newaxis,:,np.newaxis]))\n",
    "    \n",
    "    prediction,h_state=rnn(x,h_state)\n",
    "    h_state=Variable(h_state)#!!important\n",
    "    \n",
    "    loss = loss_func(prediction, y)         # calculate loss\n",
    "    optimizer.zero_grad()                   # clear gradients for this training step\n",
    "    loss.backward()                         # backpropagation, compute gradients\n",
    "    optimizer.step()                        # apply gradients\n",
    "\n",
    "    # plotting\n",
    "    plt.plot(steps, y_np.flatten(), 'r-')#flatten返回一维数组，横着展平\n",
    "    plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n",
    "    plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
